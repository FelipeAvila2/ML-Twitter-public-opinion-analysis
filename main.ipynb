{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries for the API connection\n",
    "\n",
    "import tweepy\n",
    "from tweepy.auth import OAuthHandler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a dict with the keys for the API connection\n",
    "\n",
    "secrets_dict={}\n",
    "secrets_file = open('tweepy-keys.txt')\n",
    "for line in secrets_file:\n",
    "  (key,value) = line.split(':')\n",
    "  secrets_dict[key] = value[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the API cursor\n",
    "\n",
    "auth = tweepy.OAuthHandler(secrets_dict['API Key'], secrets_dict['API secret'])\n",
    "auth.set_access_token(secrets_dict['Access token'], secrets_dict['Access secret'])\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(words, date_since, numtweet):\n",
    "\n",
    "# Creating DataFrame using pandas\n",
    "  db = pd.DataFrame(columns=['username', 'description', 'location', 'following',\n",
    "              'followers', 'totaltweets', 'retweetcount', 'text', 'hashtags'])\n",
    "\n",
    "# We are using .Cursor() to search through twitter for the required tweets.\n",
    "# The number of tweets can be restricted using .items(number of tweets)\n",
    "  tweets = tweepy.Cursor(api.search, q=words, lang=\"en\",\n",
    "            since=date_since, tweet_mode='extended').items(numtweet)\n",
    "\n",
    "# .Cursor() returns an iterable object. Each item in\n",
    "# the iterator has various attributes that you can access to\n",
    "# get information about each tweet\n",
    "  list_tweets = [tweet for tweet in tweets]\n",
    "\n",
    "# Counter to maintain Tweet Count\n",
    "  i = 1\n",
    "\n",
    "# we will iterate over each tweet in the list for extracting information about each tweet\n",
    "  for tweet in list_tweets:\n",
    "    username = tweet.user.screen_name\n",
    "    description = tweet.user.description\n",
    "    location = tweet.user.location\n",
    "    following = tweet.user.friends_count\n",
    "    followers = tweet.user.followers_count\n",
    "    totaltweets = tweet.user.statuses_count\n",
    "    retweetcount = tweet.retweet_count\n",
    "    hashtags = tweet.entities['hashtags']\n",
    "  \n",
    "# Retweets can be distinguished by a retweeted_status attribute,\n",
    "# in case it is an invalid reference, except block will be executed\n",
    "    try:\n",
    "      text = tweet.retweeted_status.full_text\n",
    "    except AttributeError:\n",
    "      text = tweet.full_text\n",
    "    hashtext = list()\n",
    "    for j in range(0, len(hashtags)):\n",
    "      hashtext.append(hashtags[j]['text'])\n",
    "\n",
    "    # Here we are appending all the extracted information in the DataFrame\n",
    "    ith_tweet = [username, description, location, following,\n",
    "          followers, totaltweets, retweetcount, text, hashtext]\n",
    "    db.loc[len(db)] = ith_tweet\n",
    "\n",
    "  \n",
    "\n",
    "# we will save our database as a CSV file.\n",
    "  return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define forloop that scrapes the necessary tweets and concatenates them\n",
    "\n",
    "import time # twitter limitates the amount of scrapping you can do, so we need to do timesleep\n",
    "from datetime import date\n",
    "\n",
    "# politic is the list of politicians to scrape for\n",
    "# Enter Date since The Tweets are required in yyyy-mm-dd\n",
    "# The minutes its the time it will spend between each iteration of the scrape\n",
    "# numtweet is the number of tweets for each hashtag\n",
    "# file is the older file that i might have and i want to concatenate with\n",
    "\n",
    "# WARNING: Remove the default politicians before deploying\n",
    "\n",
    "def scrapping_engine(date_,politic=['#JoeBiden','#BernieSanders','#MikePence','#TedCruz'], minutes=15, numtweet=500, file=0):\n",
    "\n",
    "    # we need to create a dataframe to deposit the tweets that we scrape\n",
    "\n",
    "    columns = ['target','Unnamed: 0', 'username', 'description', 'location', 'following',\n",
    "           'followers', 'totaltweets', 'retweetcount', 'text', 'hashtags'] # this are the columns that for the dataframe\n",
    "\n",
    "    politic_df = pd.DataFrame(dict(), columns=columns) # creation of the dataframe\n",
    "\n",
    "    # this is the loop for the scrapping of every politician\n",
    "\n",
    "    for element in politic:\n",
    "        subdata = scrape(element, date_, numtweet)\n",
    "        subdata['target'] = element\n",
    "        politic_df = politic_df.append(subdata)\n",
    "        time.sleep(60 * minutes) # need to take it easy!\n",
    "        \n",
    "    csv = file\n",
    "    \n",
    "    politic_df = appending(politic_df, csv)\n",
    "    \n",
    "    spams_count = dict(politic_df['text'].value_counts())\n",
    "\n",
    "    spams = []\n",
    "\n",
    "    for x,y in spams_count.items():\n",
    "        if y > 1:\n",
    "            spams.append(x)\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    politic_df = politic_df.reset_index()\n",
    "\n",
    "    for element in politic_df['text']:\n",
    "        if element in spams:\n",
    "            politic_df.drop(index=counter, inplace=True)\n",
    "        counter += 1\n",
    "    \n",
    "    new_date = 'scraped_from_' + date_ + '_to_' + str(date.today())\n",
    "    \n",
    "    if csv != 0:\n",
    "        politic_df.to_csv(new_date + '.csv', index_label=False)\n",
    "        return politic_df\n",
    "    else:\n",
    "        politic_df.to_csv(new_date + '.csv', index_label=False)\n",
    "        return politic_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that adds the newly scraped file to the rest\n",
    "\n",
    "def appending(db, file):\n",
    "    older = pd.read_csv(file)\n",
    "    return db.append(older) # returns the new database appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def politicians_input():\n",
    "    print('Enter the politicians names (separated by comma, E.g: Â´Joe Biden, Bernie SandersÂ´): ')\n",
    "    string_ = input()\n",
    "    string = string_.replace(' ','')\n",
    "    list_strings = string.split(',')\n",
    "\n",
    "    return [('#' + x) for x in list_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the politicians names (separated by comma, E.g: Â´Joe Biden, Bernie SandersÂ´): \n",
      "Joe Biden, Bernie Sanders, Ted Cruz, Mike Pence\n"
     ]
    }
   ],
   "source": [
    "to_scrape = politicians_input()\n",
    "\n",
    "# do a function for date input\n",
    "\n",
    "politic_df = scrapping_engine('2021-07-22', to_scrape, 0.1, 10, 'data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1049, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>username</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>totaltweets</th>\n",
       "      <th>retweetcount</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Michell81478626</td>\n",
       "      <td>I live in Minnesota, I love my cat, dog and bi...</td>\n",
       "      <td>Minnesota, USA</td>\n",
       "      <td>69</td>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>#Congress #chuckSchumer #nancyPelosi #democrat...</td>\n",
       "      <td>[Congress, chuckSchumer, nancyPelosi, democrat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DerekOsheaShow</td>\n",
       "      <td>Derek O'Shea Show Politically Homeless Daily C...</td>\n",
       "      <td>Everywhere you want to be</td>\n",
       "      <td>3435</td>\n",
       "      <td>781</td>\n",
       "      <td>5095</td>\n",
       "      <td>0</td>\n",
       "      <td>Who is Defunding Police | Conspiracy Theories ...</td>\n",
       "      <td>[Covid19News, JoeBiden, BreakingNews, politica...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tim20026046</td>\n",
       "      <td>White-haired, upper fifties, libertarian dad, ...</td>\n",
       "      <td></td>\n",
       "      <td>485</td>\n",
       "      <td>17</td>\n",
       "      <td>4239</td>\n",
       "      <td>98</td>\n",
       "      <td>#JoeBiden Tells The World Another Whopper \"You...</td>\n",
       "      <td>[JoeBiden]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lilgoddamn_III</td>\n",
       "      <td>#bitcoin\\nÂ§LilGoddamn</td>\n",
       "      <td>The Moon ðŸŒ•</td>\n",
       "      <td>900</td>\n",
       "      <td>297</td>\n",
       "      <td>28972</td>\n",
       "      <td>57</td>\n",
       "      <td>Democrats Future Agenda...\\n\\n#NacyPelosi :\\nL...</td>\n",
       "      <td>[NacyPelosi, JoeBiden]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LisaMaret</td>\n",
       "      <td>Founder, Tea Party WDC \"Return 2 commerce, cha...</td>\n",
       "      <td>Alexandria Va</td>\n",
       "      <td>1446</td>\n",
       "      <td>1735</td>\n",
       "      <td>69535</td>\n",
       "      <td>0</td>\n",
       "      <td>@taxreformer Big surprise, the IRS doesn't aud...</td>\n",
       "      <td>[LarcenousClass, Democrats, JoeBiden, Progress...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     target Unnamed: 0         username  \\\n",
       "0      0  #JoeBiden        NaN  Michell81478626   \n",
       "2      2  #JoeBiden        NaN   DerekOsheaShow   \n",
       "3      3  #JoeBiden        NaN      Tim20026046   \n",
       "4      4  #JoeBiden        NaN   lilgoddamn_III   \n",
       "5      5  #JoeBiden        NaN        LisaMaret   \n",
       "\n",
       "                                         description  \\\n",
       "0  I live in Minnesota, I love my cat, dog and bi...   \n",
       "2  Derek O'Shea Show Politically Homeless Daily C...   \n",
       "3  White-haired, upper fifties, libertarian dad, ...   \n",
       "4                              #bitcoin\\nÂ§LilGoddamn   \n",
       "5  Founder, Tea Party WDC \"Return 2 commerce, cha...   \n",
       "\n",
       "                    location following followers totaltweets retweetcount  \\\n",
       "0             Minnesota, USA        69        12          60            2   \n",
       "2  Everywhere you want to be      3435       781        5095            0   \n",
       "3                                  485        17        4239           98   \n",
       "4                 The Moon ðŸŒ•       900       297       28972           57   \n",
       "5              Alexandria Va      1446      1735       69535            0   \n",
       "\n",
       "                                                text  \\\n",
       "0  #Congress #chuckSchumer #nancyPelosi #democrat...   \n",
       "2  Who is Defunding Police | Conspiracy Theories ...   \n",
       "3  #JoeBiden Tells The World Another Whopper \"You...   \n",
       "4  Democrats Future Agenda...\\n\\n#NacyPelosi :\\nL...   \n",
       "5  @taxreformer Big surprise, the IRS doesn't aud...   \n",
       "\n",
       "                                            hashtags  Unnamed: 0.1  \n",
       "0  [Congress, chuckSchumer, nancyPelosi, democrat...           NaN  \n",
       "2  [Covid19News, JoeBiden, BreakingNews, politica...           NaN  \n",
       "3                                         [JoeBiden]           NaN  \n",
       "4                             [NacyPelosi, JoeBiden]           NaN  \n",
       "5  [LarcenousClass, Democrats, JoeBiden, Progress...           NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to clean the tweets\n",
    "# importing the necessaire packages\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main cleaning step\n",
    "\n",
    "def clean_up(s):\n",
    "    element1 = re.sub('(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)', '', s) # remove links\n",
    "    element2 = re.sub('[^a-zA-Z0-9]', ' ', element1) # remove non character symbols\n",
    "    element3 = re.sub('amp', '', element2) # twitter has &amp as a special character\n",
    "    return (re.sub('\\d+',' ',element3)).lower() # remove any digits and lowercase everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text\n",
    "\n",
    "def tokenize(s):\n",
    "    return word_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize function to help the next function that is lemmatize\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper() # gets first letter of POS categorization\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN) # get returns second argument if first key does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize to reduce the word to it most radical form\n",
    "\n",
    "def lemmatize(l):\n",
    "  \n",
    "    lem = WordNetLemmatizer()\n",
    "    lemmatized = [lem.lemmatize(w,get_wordnet_pos(w)) for w in l]\n",
    "    \n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the stop words\n",
    "\n",
    "def remove_stopwords(l):\n",
    "    \n",
    "    filtered_sentence = []\n",
    "    \n",
    "    for w in l:\n",
    "        if w not in stopwords.words('english'):\n",
    "            filtered_sentence.append(w)\n",
    "    \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that combines all of the cleaning functions and does everything\n",
    "\n",
    "def cleaning_engine(df,column='text'):\n",
    "    df['text_processed'] = df[column].apply(clean_up)\n",
    "    df['text_processed'] = df['text_processed'].apply(tokenize)\n",
    "    df['text_processed'] = df['text_processed'].apply(lemmatize)\n",
    "    return df['text_processed'].apply(remove_stopwords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_df['text_processed'] = cleaning_engine(politic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# think about blobbing the results\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "import itertools\n",
    "\n",
    "def get_most_common_words(amount, column=politic_df['text_processed']):\n",
    "\n",
    "    blob = column.tolist()\n",
    "\n",
    "    blob = itertools.chain.from_iterable(blob)\n",
    "\n",
    "    fdist = FreqDist(blob)\n",
    "\n",
    "    common = dict(fdist.most_common(amount)) # review this number\n",
    "\n",
    "    return list(common.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = get_most_common_words(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joebiden',\n",
       " 'tedcruz',\n",
       " 'berniesanders',\n",
       " 'biden',\n",
       " 'mikepence',\n",
       " 'trump',\n",
       " 'cnn',\n",
       " 'gop',\n",
       " 'texas',\n",
       " 'foxnews',\n",
       " 'get',\n",
       " 'covid',\n",
       " 'democrat',\n",
       " 'aoc',\n",
       " 'maga',\n",
       " 'say',\n",
       " 'rondesantis',\n",
       " 'gregabbott',\n",
       " 'variant',\n",
       " 'u',\n",
       " 'delta',\n",
       " 'texan',\n",
       " 'billlee',\n",
       " 'mikeparson',\n",
       " 'dougducey',\n",
       " 'kristinoem',\n",
       " 'kevinmccarthy',\n",
       " 'penny',\n",
       " 'msnbc',\n",
       " 'usa',\n",
       " 'want',\n",
       " 'laurenboebert',\n",
       " 'like',\n",
       " 'free',\n",
       " 'bernie',\n",
       " 'go',\n",
       " 'joe',\n",
       " 'president',\n",
       " 'lindseygraham',\n",
       " 'would',\n",
       " 'marcorubio',\n",
       " 'potus',\n",
       " 'morningjoe',\n",
       " 'abc',\n",
       " 'people',\n",
       " 'mitchmcconnell',\n",
       " 'work',\n",
       " 'state',\n",
       " 'jan',\n",
       " 'cuba',\n",
       " 'blm',\n",
       " 'need',\n",
       " 'mattgaetz',\n",
       " 'texit',\n",
       " 'order',\n",
       " 'best',\n",
       " 'party',\n",
       " 'pelosi',\n",
       " 'america',\n",
       " 'tatereeves',\n",
       " 'secede',\n",
       " 'cruz',\n",
       " 'know',\n",
       " 'think',\n",
       " 'make',\n",
       " 'nytimes',\n",
       " 'blacklivesmatter',\n",
       " 'harris',\n",
       " 'mike',\n",
       " 'cbs',\n",
       " 'news',\n",
       " 'manchin',\n",
       " 'bitcoin',\n",
       " 'nyc',\n",
       " 'lie',\n",
       " 'nothing',\n",
       " 'one',\n",
       " 'american',\n",
       " 'take',\n",
       " 'kingjames',\n",
       " 'ted',\n",
       " 'shipping',\n",
       " 'texasforever',\n",
       " 'republicoftexas',\n",
       " 'texassecede',\n",
       " 'secession',\n",
       " 'gregabott',\n",
       " 'right',\n",
       " 'politics',\n",
       " 'coribush',\n",
       " 'jimjordan',\n",
       " 'sander',\n",
       " 'try',\n",
       " 'vaxx',\n",
       " 'election',\n",
       " 'vote',\n",
       " 'mandate',\n",
       " 'even',\n",
       " 'ilharoman',\n",
       " 'majorietaylorgreene',\n",
       " 'still',\n",
       " 'thing',\n",
       " 'failure',\n",
       " 'time',\n",
       " 'give',\n",
       " 'see',\n",
       " 'mask',\n",
       " 'rashidatlaib',\n",
       " 'come',\n",
       " 'good',\n",
       " 'madisoncawthorn',\n",
       " 'town',\n",
       " 'republican',\n",
       " 'stop',\n",
       " 'change',\n",
       " 'sex',\n",
       " 'back',\n",
       " 'hall',\n",
       " 'run',\n",
       " 'florida',\n",
       " 'vaccinate',\n",
       " 'senate',\n",
       " 'kamalaharris',\n",
       " 'hand',\n",
       " 'guy',\n",
       " 'vp',\n",
       " 'country',\n",
       " 'call',\n",
       " 'many',\n",
       " 'kill',\n",
       " 'every',\n",
       " 'could',\n",
       " 'life',\n",
       " 'house',\n",
       " 'vaccine',\n",
       " 'year',\n",
       " 'tax',\n",
       " 'gun',\n",
       " 'socialism',\n",
       " 'new',\n",
       " 'live',\n",
       " 'let',\n",
       " 'day',\n",
       " 'support',\n",
       " 'fact',\n",
       " 'confirm',\n",
       " 'sentedcruz',\n",
       " 'progressive',\n",
       " 'child',\n",
       " 'pay',\n",
       " 'please',\n",
       " 'really',\n",
       " 'block',\n",
       " 'communist',\n",
       " 'also',\n",
       " 'anyone',\n",
       " 'via',\n",
       " 'ban',\n",
       " 'infrastructure',\n",
       " 'plan',\n",
       " 'bad',\n",
       " 'tell',\n",
       " 'black',\n",
       " 'senator',\n",
       " 'care',\n",
       " 'leader',\n",
       " 'donaldtrump',\n",
       " 'read',\n",
       " 'th',\n",
       " 'well',\n",
       " 'job',\n",
       " 'thehill',\n",
       " 'climate',\n",
       " 'red',\n",
       " 'diplomat',\n",
       " 'crowd',\n",
       " 'put',\n",
       " 'thought',\n",
       " 'china',\n",
       " 'man',\n",
       " 'presidenttrump',\n",
       " 'voterfraud',\n",
       " 'much',\n",
       " 'government',\n",
       " 'never',\n",
       " 'r',\n",
       " 'show',\n",
       " 'pandumbmic',\n",
       " 'secretly',\n",
       " 'congress',\n",
       " 'check',\n",
       " 'politician',\n",
       " 'policy',\n",
       " 'coronavirus',\n",
       " 'death',\n",
       " 'power',\n",
       " 'way',\n",
       " 'left',\n",
       " 'chinavirus',\n",
       " 'vax',\n",
       " 'white',\n",
       " 'enough',\n",
       " 'keep',\n",
       " 'cuban',\n",
       " 'police',\n",
       " 'stand',\n",
       " 'great',\n",
       " 'ever',\n",
       " 'spread',\n",
       " 'jim',\n",
       " 'watch',\n",
       " 'stolenpresidency',\n",
       " 'inflation',\n",
       " 'terrorist',\n",
       " 'first',\n",
       " 'republic',\n",
       " 'crime',\n",
       " 'old',\n",
       " 'bill',\n",
       " 'money',\n",
       " 'become',\n",
       " 'shirt',\n",
       " 'big',\n",
       " 'voting',\n",
       " 'sen',\n",
       " 'january',\n",
       " 'use',\n",
       " 'seanhannity',\n",
       " 'die',\n",
       " 'help',\n",
       " 'ask',\n",
       " 'mikepompeo',\n",
       " 'instead',\n",
       " 'believe',\n",
       " 'w',\n",
       " 'god',\n",
       " 'talk',\n",
       " 'point',\n",
       " 'since',\n",
       " 'dems',\n",
       " 'explode',\n",
       " 'stevescalise',\n",
       " 'world',\n",
       " 'medium',\n",
       " 'budget',\n",
       " 'start',\n",
       " 'jakepalmieri',\n",
       " 'happen',\n",
       " 'democracy',\n",
       " 'claim',\n",
       " 'question',\n",
       " 'presssec',\n",
       " 'look',\n",
       " 'office',\n",
       " 'lose',\n",
       " 'today',\n",
       " 'may',\n",
       " 'actually',\n",
       " 'mean',\n",
       " 'yet',\n",
       " 'communism',\n",
       " 'gopbetrayedamerica',\n",
       " 'hang',\n",
       " 'secret',\n",
       " 'qualification',\n",
       " 'political',\n",
       " 'barrack',\n",
       " 'comment',\n",
       " 'wait',\n",
       " 'supporter',\n",
       " 'whitehouse',\n",
       " 'health',\n",
       " 'force',\n",
       " 'remember',\n",
       " 'word',\n",
       " 'mocked',\n",
       " 'pandemic',\n",
       " 'announces',\n",
       " 'banhandguns',\n",
       " 'truth',\n",
       " 'coup',\n",
       " 'include',\n",
       " 'last',\n",
       " 'post',\n",
       " 'tweet',\n",
       " 'play',\n",
       " 'head',\n",
       " 'filibuster',\n",
       " 'rich',\n",
       " 'ninaturner',\n",
       " 'win',\n",
       " 'socialist',\n",
       " 'hold',\n",
       " 'gopcorruptionovercountry',\n",
       " 'trillion',\n",
       " 'agent',\n",
       " 'cancun',\n",
       " 'foreign',\n",
       " 'meme',\n",
       " 'book',\n",
       " 'hate',\n",
       " 'citizen',\n",
       " 'presidency',\n",
       " 'dumb',\n",
       " 'racist',\n",
       " 'clear',\n",
       " 'rnc',\n",
       " 'follow',\n",
       " 'move',\n",
       " 'townhall',\n",
       " 'youtube',\n",
       " 'lead',\n",
       " 'join',\n",
       " 'sure',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'misinformation',\n",
       " 'blame',\n",
       " 'fake',\n",
       " 'family',\n",
       " 'hell',\n",
       " 'told',\n",
       " 'barackobama',\n",
       " 'reason',\n",
       " 'must',\n",
       " 'space',\n",
       " 'dnc',\n",
       " 'border',\n",
       " 'agenda',\n",
       " 'person',\n",
       " 'sensanders',\n",
       " 'fuck',\n",
       " 'away',\n",
       " 'service',\n",
       " 'constitution',\n",
       " 'knew',\n",
       " 'insurrection',\n",
       " 'flag',\n",
       " 'tom',\n",
       " 'super',\n",
       " 'spreader',\n",
       " 'conservative',\n",
       " 'future',\n",
       " 'obama',\n",
       " 'veteran',\n",
       " 'silent',\n",
       " 'hope',\n",
       " 'seem',\n",
       " 'anti',\n",
       " 'part',\n",
       " 'arrest',\n",
       " 'always',\n",
       " 'chance',\n",
       " 'cnntownhall',\n",
       " 'cause',\n",
       " 'month',\n",
       " 'everything',\n",
       " 'virus',\n",
       " 'issue',\n",
       " 'answer',\n",
       " 'jeffbezos',\n",
       " 'bidentownhall',\n",
       " 'national',\n",
       " 'security',\n",
       " 'college',\n",
       " 'fight',\n",
       " 'create',\n",
       " 'voter',\n",
       " 'iran',\n",
       " 'shut',\n",
       " 'continue',\n",
       " 'control',\n",
       " 'face',\n",
       " 'high',\n",
       " 'something',\n",
       " 'st',\n",
       " 'real',\n",
       " 'former',\n",
       " 'feel',\n",
       " 'important',\n",
       " 'mind',\n",
       " 'funny',\n",
       " 'name',\n",
       " 'least',\n",
       " 'medicare',\n",
       " 'spending',\n",
       " 'crybabykevin',\n",
       " 'nancypelosi',\n",
       " 'vaccination',\n",
       " 'class',\n",
       " 'africa',\n",
       " 'public',\n",
       " 'official',\n",
       " 'speech',\n",
       " 'social',\n",
       " 'case',\n",
       " 'steal',\n",
       " 'absolutely',\n",
       " 'idiot',\n",
       " 'regime',\n",
       " 'admin',\n",
       " 'stay',\n",
       " 'jordan',\n",
       " 'brain',\n",
       " 'thousand',\n",
       " 'united',\n",
       " 'unitedstates',\n",
       " 'million',\n",
       " 'kid',\n",
       " 'k',\n",
       " 'tool',\n",
       " 'listen',\n",
       " 'demand',\n",
       " 'presidentbiden',\n",
       " 'fear',\n",
       " 'school',\n",
       " 'open',\n",
       " 'history',\n",
       " 'amazon',\n",
       " 'illegals',\n",
       " 'event',\n",
       " 'leave',\n",
       " 'debt',\n",
       " 'jimmy',\n",
       " 'administration',\n",
       " 'thereidout',\n",
       " 'message',\n",
       " 'jerusalem',\n",
       " 'someone',\n",
       " 'murder',\n",
       " 'brand',\n",
       " 'hillaryclinton',\n",
       " 'without',\n",
       " 'berniememes',\n",
       " 'donald',\n",
       " 'thesquad',\n",
       " 'full',\n",
       " 'feelthebern',\n",
       " 'end',\n",
       " 'jail',\n",
       " 'moscowmitch',\n",
       " 'traitor',\n",
       " 'action',\n",
       " 'fix',\n",
       " 'line',\n",
       " 'conspiracy',\n",
       " 'comedy',\n",
       " 'another',\n",
       " 'sound',\n",
       " 'link',\n",
       " 'cougar',\n",
       " 'hp',\n",
       " 'fsu',\n",
       " 'rsa',\n",
       " 'fair',\n",
       " 'aka',\n",
       " 'flee',\n",
       " 'hear',\n",
       " 'human',\n",
       " 'share',\n",
       " 'problem',\n",
       " 'goal',\n",
       " 'literally',\n",
       " 'bbc',\n",
       " 'sleepyjoe',\n",
       " 'rock',\n",
       " 'next',\n",
       " 'fox',\n",
       " 'jeff',\n",
       " 'corrupt',\n",
       " 'find',\n",
       " 'special',\n",
       " 'cnnpolitics',\n",
       " 'twitter',\n",
       " 'imagine',\n",
       " 'quote',\n",
       " 'gt',\n",
       " 'return',\n",
       " 'bidenadministration',\n",
       " 'sorry',\n",
       " 'interest',\n",
       " 'tfg',\n",
       " 'ohio',\n",
       " 'c',\n",
       " 'russia',\n",
       " 'anything',\n",
       " 'attack',\n",
       " 'woman',\n",
       " 'caign',\n",
       " 'friend',\n",
       " 'fauci',\n",
       " 'thom',\n",
       " 'hartmann',\n",
       " 'maddow',\n",
       " 'far',\n",
       " 'war',\n",
       " 'shit',\n",
       " 'gigantically',\n",
       " 'turn',\n",
       " 'liberal',\n",
       " 'system',\n",
       " 'fly',\n",
       " 'thank',\n",
       " 'generation',\n",
       " 'bet',\n",
       " 'damn',\n",
       " 'vermont',\n",
       " 'elizabethwarren',\n",
       " 'hearing',\n",
       " 'berniesandersmittens',\n",
       " 'cuz',\n",
       " 'gopliesabouteverything',\n",
       " 'seek',\n",
       " 'attempt',\n",
       " 'kind',\n",
       " 'freedom',\n",
       " 'democratic',\n",
       " 'article',\n",
       " 'stupidity',\n",
       " 'nominee',\n",
       " 'capitol',\n",
       " 'betrayal',\n",
       " 'newsweek',\n",
       " 'hey',\n",
       " 'treason',\n",
       " 'suck',\n",
       " 'cancuncruz',\n",
       " 'tx',\n",
       " 'randpaul',\n",
       " 'stimulus',\n",
       " 'break',\n",
       " 'story',\n",
       " 'protest',\n",
       " 'wrong',\n",
       " 'everyone',\n",
       " 'wish',\n",
       " 'obvious',\n",
       " 'doubt',\n",
       " 'senile',\n",
       " 'sanction',\n",
       " 'july',\n",
       " 'newslink',\n",
       " 'russian',\n",
       " 'newsmax',\n",
       " 'worth',\n",
       " 'host',\n",
       " 'southern',\n",
       " 'menu',\n",
       " 'chickenfriedp',\n",
       " 'protect',\n",
       " 'regard',\n",
       " 'half',\n",
       " 'allow',\n",
       " 'price',\n",
       " 'son',\n",
       " 'involve',\n",
       " 'crypto',\n",
       " 'single',\n",
       " 'parent',\n",
       " 'racism',\n",
       " 'g',\n",
       " 'labor',\n",
       " 'maybe',\n",
       " 'summer',\n",
       " 'michael',\n",
       " 'israel',\n",
       " 'audience',\n",
       " 'tuckercarlson',\n",
       " 'nice',\n",
       " 'evil',\n",
       " 'matter',\n",
       " 'wear',\n",
       " 'save',\n",
       " 'morning',\n",
       " 'welcome',\n",
       " 'honest',\n",
       " 'set',\n",
       " 'across',\n",
       " 'invest',\n",
       " 'economy',\n",
       " 'deserve',\n",
       " 'less',\n",
       " 'chinese',\n",
       " 'knee',\n",
       " 'infrastructurebill',\n",
       " 'debate',\n",
       " 'stephmillershow',\n",
       " 'randirhodes',\n",
       " 'business',\n",
       " 'others',\n",
       " 'dr',\n",
       " 'proud',\n",
       " 'slow',\n",
       " 'voteblue',\n",
       " 'dad',\n",
       " 'slam',\n",
       " 'criminal',\n",
       " 'age',\n",
       " 'deltavariant',\n",
       " 'likely',\n",
       " 'nft',\n",
       " 'respect',\n",
       " 'wednesday',\n",
       " 'daily',\n",
       " 'bos',\n",
       " 'hurt',\n",
       " 'understand',\n",
       " 'liar',\n",
       " 'wonder',\n",
       " 'domain',\n",
       " 'top',\n",
       " 'wage',\n",
       " 'tuckercarlsontonight',\n",
       " 'ingrahamangle',\n",
       " 'b',\n",
       " 'ok',\n",
       " 'law',\n",
       " 'presidential',\n",
       " 'facebook',\n",
       " 'seat',\n",
       " 'allows',\n",
       " 'paid',\n",
       " 'piece',\n",
       " 'weak',\n",
       " 'dog',\n",
       " 'pro',\n",
       " 'oppose',\n",
       " 'wife',\n",
       " 'though',\n",
       " 'living',\n",
       " 'primary',\n",
       " 'oh',\n",
       " 'mouth',\n",
       " 'car',\n",
       " 'harm',\n",
       " 'sabotage',\n",
       " 'majoriethemaniac',\n",
       " 'lone',\n",
       " 'star',\n",
       " 'dept',\n",
       " 'chuckschumer',\n",
       " 'vacation',\n",
       " 'breakingnews',\n",
       " 'career',\n",
       " 'photo',\n",
       " 'constituent',\n",
       " 'guarantee',\n",
       " 'yahoo',\n",
       " 'mate',\n",
       " 'little',\n",
       " 'housegop',\n",
       " 'senategop',\n",
       " 'propaganda',\n",
       " 'bloomberg',\n",
       " 'boat',\n",
       " 'christ',\n",
       " 'bipartisan',\n",
       " 'account',\n",
       " 'afraid',\n",
       " 'fund',\n",
       " 'deny',\n",
       " 'thedemocrats',\n",
       " 'popular',\n",
       " 'elonmusk',\n",
       " 'worker',\n",
       " 'sit',\n",
       " 'sign',\n",
       " 'source',\n",
       " 'hard',\n",
       " 'hack',\n",
       " 'science',\n",
       " 'finally',\n",
       " 'mother',\n",
       " 'receive',\n",
       " 'germany',\n",
       " 'consider',\n",
       " 'leftist',\n",
       " 'kkk',\n",
       " 'outside',\n",
       " 'place',\n",
       " 'ready',\n",
       " 'concern',\n",
       " 'long',\n",
       " 'crt',\n",
       " 'uk',\n",
       " 'housing',\n",
       " 'miss',\n",
       " 'member',\n",
       " 'appear',\n",
       " 'actual',\n",
       " 'gopleader',\n",
       " 'commit',\n",
       " 'v',\n",
       " 'yes',\n",
       " 'true',\n",
       " 'buy',\n",
       " 'hunterbiden',\n",
       " 'meet',\n",
       " 'dear',\n",
       " 'na',\n",
       " 'wing',\n",
       " 'patriot',\n",
       " 'express',\n",
       " 'entire',\n",
       " 'else',\n",
       " 'advice',\n",
       " 'tv',\n",
       " 'international',\n",
       " 'charge',\n",
       " 'reach',\n",
       " 'omg',\n",
       " 'steve',\n",
       " 'heart',\n",
       " 'eu',\n",
       " 'gqp',\n",
       " 'thursday',\n",
       " 'design',\n",
       " 'throw',\n",
       " 'team',\n",
       " 'al',\n",
       " 'palestine',\n",
       " 'smart',\n",
       " 'bidenharris',\n",
       " 'might',\n",
       " 'possibility',\n",
       " 'rate',\n",
       " 'putin',\n",
       " 'shaun',\n",
       " 'possible',\n",
       " 'bring',\n",
       " 'information',\n",
       " 'two',\n",
       " 'bordercrisis',\n",
       " 'dc',\n",
       " 'proof',\n",
       " 'corporate',\n",
       " 'capitalism',\n",
       " 'statement',\n",
       " 'especially',\n",
       " 'investigate',\n",
       " 'either',\n",
       " 'together',\n",
       " 'kentucky',\n",
       " 'report',\n",
       " 'tough',\n",
       " 'speakerpelosi',\n",
       " 'group',\n",
       " 'mad',\n",
       " 'bezos',\n",
       " 'struggle',\n",
       " 'saw',\n",
       " 'disinformation',\n",
       " 'blueorigin',\n",
       " 'puppet',\n",
       " 'berniesmittens',\n",
       " 'wtf',\n",
       " 'dream',\n",
       " 'sh',\n",
       " 'ilhanomar',\n",
       " 'laugh',\n",
       " 'blast',\n",
       " 'billionaire',\n",
       " 'vt',\n",
       " 'donate',\n",
       " 'probably',\n",
       " 'push',\n",
       " 'censorship',\n",
       " 'proact',\n",
       " 'embargo',\n",
       " 'crawl',\n",
       " 'graham',\n",
       " 'apparently',\n",
       " 'guess',\n",
       " 'covidiots',\n",
       " 'opinion',\n",
       " 'program',\n",
       " 'simply',\n",
       " 'speak',\n",
       " 'civil',\n",
       " 'alabama',\n",
       " 'fail',\n",
       " 'radical',\n",
       " 'grandpa',\n",
       " 'angeles',\n",
       " 'thevoice',\n",
       " 'rhonj',\n",
       " 'rioter',\n",
       " 'poll',\n",
       " 'corruption',\n",
       " 'teach',\n",
       " 'diversion',\n",
       " 'foreigninterference',\n",
       " 'destruction',\n",
       " 'controversy',\n",
       " 'loser',\n",
       " 'confirmation',\n",
       " 'tuckeriskillingus',\n",
       " 'theory',\n",
       " 'activist',\n",
       " 'built',\n",
       " 'replace',\n",
       " 'irs',\n",
       " 'audit',\n",
       " 'troop',\n",
       " 'schumer',\n",
       " 'due',\n",
       " 'govabbott',\n",
       " 'ballot',\n",
       " 'doj',\n",
       " 'record',\n",
       " 'ialonecanfixit',\n",
       " 'hero',\n",
       " 'certify',\n",
       " 'pretty',\n",
       " 'ticket',\n",
       " 'suspect',\n",
       " 'muslim',\n",
       " 'california',\n",
       " 'consequence',\n",
       " 'nra',\n",
       " 'individual',\n",
       " 'uprising',\n",
       " 'mess',\n",
       " 'politico',\n",
       " 'oann',\n",
       " 'foxbusiness',\n",
       " 'cnbc',\n",
       " 'uscongress',\n",
       " 'retirement',\n",
       " 'fun',\n",
       " 'stupid',\n",
       " 'miami',\n",
       " 'appreciate',\n",
       " 'home',\n",
       " 'basement',\n",
       " 'mid',\n",
       " 'except',\n",
       " 'screw',\n",
       " 'around',\n",
       " 'option',\n",
       " 'dementia',\n",
       " 'ussr',\n",
       " 'card',\n",
       " 'mental',\n",
       " 'etc',\n",
       " 'community',\n",
       " 'survive',\n",
       " 'restaurant',\n",
       " 'act',\n",
       " 'visit',\n",
       " 'stimuluschecks',\n",
       " 'leadership',\n",
       " 'tosaveamerica',\n",
       " 'byrd',\n",
       " 'stuff',\n",
       " 'side',\n",
       " 'citizenship',\n",
       " 'company',\n",
       " 'blue',\n",
       " 'exclusive',\n",
       " 'race',\n",
       " 'false',\n",
       " 'refuse',\n",
       " 'raise',\n",
       " 'aid',\n",
       " 'info',\n",
       " 'mention',\n",
       " 'un',\n",
       " 'increase',\n",
       " 'response',\n",
       " 'immigration',\n",
       " 'voice',\n",
       " 'non',\n",
       " 'project',\n",
       " 'speaks',\n",
       " 'gon',\n",
       " 'clip',\n",
       " 'trend',\n",
       " 'donlemon',\n",
       " 'ignore',\n",
       " 'shot',\n",
       " 'chicago',\n",
       " 'indiana',\n",
       " 'deal',\n",
       " 'catch',\n",
       " 'fully',\n",
       " 'mexico',\n",
       " 'venezuela',\n",
       " 'carter',\n",
       " 'base',\n",
       " 'education',\n",
       " 'healthcare',\n",
       " 'highlight',\n",
       " 'accuse',\n",
       " 'chrislhayes',\n",
       " 'brought',\n",
       " 'crow',\n",
       " 'assault',\n",
       " 'train',\n",
       " 'learn',\n",
       " 'surge',\n",
       " 'soldier',\n",
       " 'complicit',\n",
       " 'minute',\n",
       " 'sticker',\n",
       " 'executive',\n",
       " 'customer',\n",
       " 'flotus',\n",
       " 'vice',\n",
       " 'govt',\n",
       " 'week',\n",
       " 'soon',\n",
       " 'wow',\n",
       " 'frustration',\n",
       " 'plead',\n",
       " 'inoculate',\n",
       " 'print',\n",
       " 'storm',\n",
       " 'poopsident',\n",
       " 'advantage',\n",
       " 'sleepy',\n",
       " 'nfts',\n",
       " 'nftart',\n",
       " 'nftartist',\n",
       " 'nftcommunity',\n",
       " 'schedule',\n",
       " 'earth',\n",
       " 'legislation',\n",
       " 'bother',\n",
       " 'reality',\n",
       " 'crisis',\n",
       " 'usnews',\n",
       " 'insane',\n",
       " 'liberty',\n",
       " 'favor',\n",
       " 'criticalracetheory',\n",
       " 'within',\n",
       " 'jenpsaki',\n",
       " 'john',\n",
       " 'already',\n",
       " 'dom',\n",
       " 'fast',\n",
       " 'possibly',\n",
       " 'glad',\n",
       " 'game',\n",
       " 'clearly',\n",
       " 'governor',\n",
       " 'shop',\n",
       " 'discus',\n",
       " 'lion',\n",
       " 'asshole',\n",
       " 'oligarchy',\n",
       " 'trumpliedpeopledied',\n",
       " 'cc',\n",
       " 'daughter',\n",
       " 'fool',\n",
       " 'clinton',\n",
       " 'nightmare',\n",
       " 'agree',\n",
       " 'cap',\n",
       " 'waste',\n",
       " 'mitten',\n",
       " 'dore',\n",
       " 'dead',\n",
       " 'approve',\n",
       " 'dollar',\n",
       " 'forgot',\n",
       " 'psa',\n",
       " 'sexist',\n",
       " 'worry',\n",
       " 'castro',\n",
       " 'historic',\n",
       " 'berniebros',\n",
       " 'economics',\n",
       " 'paradise',\n",
       " 'ugly',\n",
       " 'despise',\n",
       " 'illegal',\n",
       " 'idea',\n",
       " 'wealth',\n",
       " 'inequality',\n",
       " 'reform',\n",
       " 'particularly',\n",
       " 'trash',\n",
       " 'planet',\n",
       " 'willing',\n",
       " 'lol',\n",
       " 'diplomacy',\n",
       " 'honeymoon',\n",
       " 'rally',\n",
       " 'skin',\n",
       " 'spine',\n",
       " 'cancel',\n",
       " 'strong',\n",
       " 'huge',\n",
       " 'finance',\n",
       " 'bigtech',\n",
       " 'hongkong',\n",
       " 'raft',\n",
       " 'sail']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add anything that was not included in that list\n",
    "\n",
    "#spams.append('good morning happy friday mikepence even trust secret service protect jan th fear coup maga gallows ready still call donald trump personal friend mary trump need write book abt psycho mike penny morningjoe penny co rz sbyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now can start developing the features for our model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# first i will vectorize all of the words in each tweet by the most common words\n",
    "\n",
    "bow_vect = CountVectorizer(vocabulary=most_common, max_features=1000)\n",
    "\n",
    "# fit creates one entry for each different word seen\n",
    "\n",
    "X = bow_vect.fit_transform(politic_df['blobbed']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to standardize the features for improving the model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create object\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit\n",
    "\n",
    "scaler.fit(X)\n",
    "\n",
    "# transform \n",
    "\n",
    "X_scaled = scaler.transform(as_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
